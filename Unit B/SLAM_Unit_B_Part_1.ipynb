{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "723c82466d173ece272a4b938421f1c6",
     "grade": false,
     "grade_id": "cell-345b317c84d884ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# SLAM Unit B - Part 1\n",
    "In this unit, Unit B, we will learn to use the sensor data to improve the robot's state.\n",
    "## Localization using *features*\n",
    "In our first approach, we will use so-called *features*, or *landmarks*, to reason about the *pose* (the position and orientation) of the robot. In our case, the features are the cylinders which are present in our arena and which we detected in Unit A, from the measurements of our laser scanner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YouTube = True  # Uncomment this line to get YouTube videos instead of TIB AV.\n",
    "# If you don't see a video below, run this cell.\n",
    "from IPython.display import IFrame\n",
    "IFrame(\"https://www.youtube.com/embed/AbmhPu6lgUs\" if \"YouTube\" in globals() else \"//av.tib.eu/player/48983\",\n",
    "       width=560, height=315)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d07183057e2f159e6be6a5ecaac43e3b",
     "grade": false,
     "grade_id": "cell-1871fc0541ad987f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Here is the code which computes the world coordinates for the detected landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each cylinder in the scan, find its cartesian coordinates,\n",
    "# in the world coordinate system.\n",
    "# Write the result to a file which contains all cylinders, for all scans.\n",
    "# 04_a_project_landmarks\n",
    "from lego_robot import *\n",
    "from slam_b_library import filter_step, compute_derivative,\\\n",
    "     find_cylinders, compute_cartesian_coordinates\n",
    "\n",
    "# Put all cylinder extraction and position finding into one function.\n",
    "def compute_scanner_cylinders(scan, jump, min_dist, cylinder_offset):\n",
    "    der = compute_derivative(scan, min_dist)\n",
    "    cylinders = find_cylinders(scan, der, jump, min_dist)\n",
    "    scanner_cylinders = compute_cartesian_coordinates(cylinders, cylinder_offset)\n",
    "    return scanner_cylinders\n",
    "\n",
    "# Utility to write a list of cylinders to (one line of) a given file.\n",
    "# Line header defines the start of each line, e.g. \"D C\" for a detected\n",
    "# cylinder or \"W C\" for a world cylinder.\n",
    "def write_cylinders(file_desc, line_header, cylinder_list):\n",
    "    print(line_header, end=' ', file=file_desc)\n",
    "    for c in cylinder_list:\n",
    "        print(\"%.1f %.1f\" % c, end=' ', file=file_desc)\n",
    "    print(file=file_desc)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # The constants we used for the filter_step.\n",
    "    scanner_displacement = 30.0\n",
    "    ticks_to_mm = 0.349\n",
    "    robot_width = 150.0\n",
    "\n",
    "    # The constants we used for the cylinder detection in our scan.    \n",
    "    minimum_valid_distance = 20.0\n",
    "    depth_jump = 100.0\n",
    "    cylinder_offset = 90.0\n",
    "\n",
    "    # The start pose we obtained miraculously.\n",
    "    pose = (1850.0, 1897.0, 3.717551306747922)\n",
    "\n",
    "    # Read the logfile which contains all scans.\n",
    "    logfile = LegoLogfile()\n",
    "    logfile.read(\"robot4_motors.txt\")\n",
    "    logfile.read(\"robot4_scan.txt\")\n",
    "\n",
    "    # Iterate over all positions.\n",
    "    out_file = open(\"project_landmarks.txt\", \"w\")\n",
    "    for i in range(len(logfile.scan_data)):\n",
    "        # Compute the new pose.\n",
    "        pose = filter_step(pose, logfile.motor_ticks[i],\n",
    "                           ticks_to_mm, robot_width,\n",
    "                           scanner_displacement)\n",
    "\n",
    "        # Extract cylinders, also convert them to world coordinates.\n",
    "        cartesian_cylinders = compute_scanner_cylinders(\n",
    "            logfile.scan_data[i],\n",
    "            depth_jump, minimum_valid_distance, cylinder_offset)\n",
    "        world_cylinders = [LegoLogfile.scanner_to_world(pose, c)\n",
    "                           for c in cartesian_cylinders]\n",
    "\n",
    "        # Write results to file.\n",
    "        # The pose.\n",
    "        print(\"F %f %f %f\" % pose, file=out_file)\n",
    "        # The detected cylinders in the scanner's coordinate system.\n",
    "        write_cylinders(out_file, \"D C\", cartesian_cylinders)\n",
    "        # The detected cylinders in the world coordinate system.\n",
    "        write_cylinders(out_file, \"W C\", world_cylinders)\n",
    "\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd8fc14a81e88abd447ea7134c80d9c8",
     "grade": false,
     "grade_id": "cell-50cfb508c2d89769",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Let's have a look at the produced cylinder (world) coordinates.\n",
    "This reproduces the results shown in the video.\n",
    "\n",
    "You can see that in the beginning, the detected landmarks, projected to world coordinates, fit reasonably well to the landmarks in the map. However, as the pose of the robot starts to drift away from the true pose, during the first left turn, the landmarks also drift away from their expected (map) location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipy_logfile_viewer as lfv\n",
    "v = lfv.IPYLogfileViewer(files=[\"project_landmarks.txt\", \"robot_arena_landmarks.txt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d31ef3486e0ffda1bb55d174c709727",
     "grade": false,
     "grade_id": "cell-0fa541ccb364312b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Assignment of cylinders\n",
    "In order to use the cylinders for localization, we must first find correspondences between the landmarks we extract from the laser scanner measurements, and the landmarks in our map. This will be our first programming assignment.\n",
    "### Programming assignment: landmark assignment (15 Points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0d93f41e9978c365ebfd9226db0b070",
     "grade": false,
     "grade_id": "cell-bea8a71574e200cd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Given a list of cylinders (points) and reference_cylinders:\n",
    "# For every cylinder, find the closest reference_cylinder and add\n",
    "# the index pair (i, j), where i is the index of the cylinder, and\n",
    "# j is the index of the reference_cylinder, to the result list.\n",
    "def find_cylinder_pairs(cylinders, reference_cylinders, max_radius):\n",
    "    cylinder_pairs = []\n",
    "\n",
    "    # Make a loop over all cylinders and reference_cylinders.\n",
    "    # In the loop, if cylinders[i] is closest to reference_cylinders[j],\n",
    "    # and their distance is below max_radius, then add the\n",
    "    # tuple (i,j) to cylinder_pairs, i.e., cylinder_pairs.append( (i,j) ).\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return cylinder_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f8208430ca2f7bc4a5aac2bbabd5bff",
     "grade": false,
     "grade_id": "cell-12ee98cb6ac27bb7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Let's test some cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e2a5641d4b8061cb664e956cc0768bb",
     "grade": true,
     "grade_id": "cell-6ce57b06c554c602",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def public_test(the_find_cylinder_pairs):\n",
    "    # Test cases: (cylinders, reference, radius, solution).\n",
    "    test_cases = [\n",
    "        # Test 0: (1, 1) should match (0, 0) when radius is 2.\n",
    "        ([(1,1)], [(0,0)], 2, [(0,0)]),\n",
    "\n",
    "        # Test 1: Three points, not in order: 0, 1, 2 matches 1, 2, 0.\n",
    "        ([(0,0), (10,0), (10,10)], [(11,9), (1,1), (9,-1)], 2,\n",
    "         [(0,1), (1,2), (2,0)]),\n",
    "\n",
    "        # Test 2: If there are several alternatives, take the closest one.\n",
    "        ([(0,0)], [(1,0), (1,1), (0,5), (10,1), (0.5,0.5), (0,1)], 6, [(0,4)]),\n",
    "\n",
    "        # Test 3: If all solutions are beyond the radius, the result is empty.\n",
    "        ([(101,102)], [(0,0), (1,1), (0,2)], 10, []),\n",
    "\n",
    "        # Test 4, 5, 6, 7: Test that radius is used, not radius squared etc.\n",
    "        ([(0,0)], [(0, 4.001)], 4, []),\n",
    "        ([(0,0)], [(0, 3.999)], 4, [(0,0)]),\n",
    "        ([(1.5,1.5)], [(1,1), (2,2)], 0.7, []), # sqrt(2)/2 = 0.7071 > 0.7.\n",
    "        ([(1.5,1.5)], [(1,0.999), (2,2)], 0.7072, [(0,1)]),\n",
    "\n",
    "        # Test 8, 9: If one of the lists is empty, the result is empty.\n",
    "        ([(0,0), (1,1)], [], 0.1, []),\n",
    "        ([], [(0,0), (1,1)], 0.1, []),\n",
    "    ]\n",
    "\n",
    "    # Run all tests.\n",
    "    for i, test in enumerate(test_cases):\n",
    "        try:\n",
    "            result = the_find_cylinder_pairs(*test[0:3])\n",
    "            if sorted(result) != sorted(test[3]):\n",
    "                print(\"Test number %d failed.\" % i)\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(\"Test number %d crashed with exception:\" % i, repr(e))\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "assert(public_test(find_cylinder_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "18d0f9ae9f24c2c2d1b7f4cc11310e51",
     "grade": false,
     "grade_id": "cell-eae01e9b8a55ac0a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Now we run it and then use the logfile viewer to visually check the assignment results.\n",
    "This should look like shown in the video. Whenever a landmark was successfully assigned to a measured cylinder, it is marked (by an extra dot in its center)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each cylinder in the scan, find its cartesian coordinates,\n",
    "# in the world coordinate system. Then, find the closest point\n",
    "# in the reference cylinder dataset and output it.\n",
    "# 04_b_find_cylinder_pairs\n",
    "from lego_robot import *\n",
    "from slam_b_library import filter_step\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # The constants we used for the filter_step.\n",
    "    scanner_displacement = 30.0\n",
    "    ticks_to_mm = 0.349\n",
    "    robot_width = 150.0\n",
    "\n",
    "    # The constants we used for the cylinder detection in our scan.    \n",
    "    minimum_valid_distance = 20.0\n",
    "    depth_jump = 100.0\n",
    "    cylinder_offset = 90.0\n",
    "\n",
    "    # The maximum distance allowed for cylinder assignment.\n",
    "    max_cylinder_distance = 300.0\n",
    "\n",
    "    # The start pose we obtained miraculously.\n",
    "    pose = (1850.0, 1897.0, 3.717551306747922)\n",
    "\n",
    "    # Read the logfile which contains all scans.\n",
    "    logfile = LegoLogfile()\n",
    "    logfile.read(\"robot4_motors.txt\")\n",
    "    logfile.read(\"robot4_scan.txt\")\n",
    "\n",
    "    # Also read the reference cylinders (the map).\n",
    "    logfile.read(\"robot_arena_landmarks.txt\")\n",
    "    reference_cylinders = [l[1:3] for l in logfile.landmarks]\n",
    "\n",
    "    # Iterate over all positions.\n",
    "    out_file = open(\"find_cylinder_pairs.txt\", \"w\")\n",
    "    for i in range(len(logfile.scan_data)):\n",
    "        # Compute the new pose.\n",
    "        pose = filter_step(pose, logfile.motor_ticks[i],\n",
    "                           ticks_to_mm, robot_width,\n",
    "                           scanner_displacement)\n",
    "\n",
    "        # Extract cylinders, also convert them to world coordinates.\n",
    "        cartesian_cylinders = compute_scanner_cylinders(\n",
    "            logfile.scan_data[i],\n",
    "            depth_jump, minimum_valid_distance, cylinder_offset)\n",
    "        world_cylinders = [LegoLogfile.scanner_to_world(pose, c)\n",
    "                           for c in cartesian_cylinders]\n",
    "\n",
    "        # For every cylinder, find the closest reference cylinder.\n",
    "        cylinder_pairs = find_cylinder_pairs(\n",
    "            world_cylinders, reference_cylinders, max_cylinder_distance)\n",
    "\n",
    "        # Write to file.\n",
    "        # The pose.\n",
    "        print(\"F %f %f %f\" % pose, file=out_file)\n",
    "        # The detected cylinders in the scanner's coordinate system.\n",
    "        write_cylinders(out_file, \"D C\", cartesian_cylinders)\n",
    "        # The reference cylinders which were part of a cylinder pair.\n",
    "        write_cylinders(out_file, \"W C\",\n",
    "            [reference_cylinders[j[1]] for j in cylinder_pairs])\n",
    "\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipy_logfile_viewer as lfv\n",
    "v = lfv.IPYLogfileViewer(files=[\"find_cylinder_pairs.txt\", \"robot_arena_landmarks.txt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "85892dd3f7cb2ae98f1060c27c9f0f89",
     "grade": false,
     "grade_id": "cell-14f118e621425f11",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Estimation of a similarity transform\n",
    "After we know the correspondences, we can use them to compute a transformation between the measured landmarks and the landmarks in the map. We will use a similarity transform for that. After we have found this transformation, we can align the measured landmarks to the landmarks in the map, and more importantly, we can use it to correct the position and orientation (pose) of the robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e856022f4b76835fd4314bbbe7db0ca4",
     "grade": false,
     "grade_id": "cell-a16a71e79fa68e76",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# If you don't see a video below, run this cell.\n",
    "from IPython.display import IFrame\n",
    "IFrame(\"https://www.youtube.com/embed/2Zf7J6cKpOQ\" if \"YouTube\" in globals() else \"//av.tib.eu/player/48984\",\n",
    "       width=560, height=315)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8604e245a48f99dbe88d9f738cd048d1",
     "grade": false,
     "grade_id": "cell-d47795e9d56224e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "###  Programming assignment: using the cylinder pairs, find the transformation (20 Points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2dfc3d71392c8fc90546ec2ba95af36d",
     "grade": false,
     "grade_id": "cell-7617ae387f082093",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: In this notebook you won't have to insert your implementation of find_cylinder_pairs()\n",
    "#       here, since your function from above is just taken. If this does not work, make sure\n",
    "#       to execute the cells above.\n",
    "\n",
    "# Given a point list, return the center of mass.\n",
    "def compute_center(point_list):\n",
    "    # Safeguard against empty list.\n",
    "    if not point_list:\n",
    "        return (0.0, 0.0)\n",
    "    # If not empty, sum up and divide.\n",
    "    sx = sum([p[0] for p in point_list])\n",
    "    sy = sum([p[1] for p in point_list])\n",
    "    return (float(sx) / len(point_list), float(sy) / len(point_list))\n",
    "\n",
    "# Given a similarity transformation:\n",
    "# trafo = (scale, cos(angle), sin(angle), x_translation, y_translation)\n",
    "# and a point p = (x, y), return the transformed point.\n",
    "def apply_transform(trafo, p):\n",
    "    la, c, s, tx, ty = trafo\n",
    "    lac = la * c\n",
    "    las = la * s\n",
    "    x = lac * p[0] - las * p[1] + tx\n",
    "    y = las * p[0] + lac * p[1] + ty\n",
    "    return (x, y)\n",
    "\n",
    "# Given a left_list of points and a right_list of points, compute\n",
    "# the parameters of a similarity transform: scale, rotation, translation.\n",
    "# If fix_scale is True, use the fixed scale of 1.0.\n",
    "# The returned value is a tuple of:\n",
    "# (scale, cos(angle), sin(angle), x_translation, y_translation)\n",
    "# i.e., the rotation angle is not given in radians, but rather in terms\n",
    "# of the cosine and sine.\n",
    "def estimate_transform(left_list, right_list, fix_scale = False):\n",
    "    # Compute left and right center.\n",
    "    lc = compute_center(left_list)\n",
    "    rc = compute_center(right_list)\n",
    "    \n",
    "    # Needs to compute: lambda, c, s, and tx, ty, where c and s are\n",
    "    # the cosine and sine of the rotation angle, i.e. (c, s) is a\n",
    "    # unit vector indicating the rotation (i.e. where the x-axis\n",
    "    # points to after rotation).\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return la, c, s, tx, ty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5170b4315b487614f5ca441eeaa2521d",
     "grade": false,
     "grade_id": "cell-1e75eec751194f58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Let's test this.\n",
    "Note that if you get test errors like *division by zero*, it may be the case that your code does not handle singular cases well. You may also get hints from the SLAM B 03 video below how to handle those cases properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f42f8df2048b0e25925b488995834a3a",
     "grade": true,
     "grade_id": "cell-cda3b8bd3980ed7c",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "# A non-numpy parameter comparison function which tolerates small errors.\n",
    "def similar_transform_parameters(trafo_a, trafo_b):\n",
    "    if trafo_a == None or trafo_b == None:\n",
    "        return trafo_a == trafo_b\n",
    "    return len(trafo_a)== 5 and len(trafo_b)==5 and\\\n",
    "           max(abs(a-b) for (a,b) in zip(trafo_a, trafo_b)) < 0.0001\n",
    "\n",
    "# The test function.\n",
    "def public_test(the_estimate_transform):\n",
    "    # test_cases is a list of tuples. Each tuple is:\n",
    "    # (left_list, right_list, fix_scale, error text).\n",
    "    test_cases = [\n",
    "        # Test 0: 3 points which are perfectly aligned, no fixed scale.\n",
    "        ([(0.0,0.0), (1.0,0.0), (0.0, 1.0)],\n",
    "         [(0.0,0.0), (1.0,0.0), (0.0, 1.0)],\n",
    "         False, (1.0, 1.0, 0.0, 0.0, 0.0)),\n",
    "        \n",
    "        # Test 1: 3 points which are perfectly aligned, w/ fixed scale.\n",
    "        ([(0.0,0.0), (1.0,0.0), (0.0, 1.0)],\n",
    "         [(0.0,0.0), (1.0,0.0), (0.0, 1.0)],\n",
    "         True, (1.0, 1.0, 0.0, 0.0, 0.0)),\n",
    "        \n",
    "        # Test 2: 3 points, almost aligned, no fixed scale.\n",
    "        ([(0.0,0.0), (1.0,0.0), (0.0, 1.0)],\n",
    "         [(0.1,0.0), (1.0,0.1), (0.1, 1.0)],\n",
    "         False, (0.9273618495495702, 0.9996349698728535, 0.02701716134791493,\n",
    "                 0.09934378339382115, 0.049307326915700056)),\n",
    "        \n",
    "        # Test 3: 3 points, almost aligned, w/ fixed scale.\n",
    "        ([(0.0,0.0), (1.0,0.0), (0.0, 1.0)],\n",
    "         [(0.1,0.0), (1.0,0.1), (0.1, 1.0)],\n",
    "         True, (1.0, 0.9996349698728535, 0.02701716134791493,\n",
    "                0.07579406382502057, 0.02444928959307724)),\n",
    "\n",
    "        # Test 4, 5: 2 points still work.\n",
    "        ([(0.0,0.0), (1.0,1.0),],\n",
    "         [(0.0,0.0), (1.1,1.1)],\n",
    "         False, (1.1, 1.0, 0.0, 0.0, 0.0)),\n",
    "        ([(0.0,0.0), (1.0,1.0),],\n",
    "         [(0.0,0.0), (1.1,1.1)],\n",
    "         True, (1.0, 1.0, 0.0, 0.05, 0.05)),\n",
    "\n",
    "        # Test 6: 1 point always fails, because the transform cannot be\n",
    "        # estimated from a single point. Your code shouldn't crash.\n",
    "        ([(123.0, 234.0)],\n",
    "         [(234.0, 345.0)],\n",
    "         True, None),\n",
    "\n",
    "        # Test 7, 8: all identical points also fails, because the transform\n",
    "        # cannot be estimated from a single point. Your code shouldn't crash.\n",
    "        ([(123.0, 234.0), (123.0, 234.0), (123.0, 234.0)],\n",
    "         [(0.0,0.0), (1.1,1.1), (2.2,2.2)],\n",
    "         True, None),\n",
    "        ([(0.0,0.0), (1.1,1.1), (2.2,2.2)],\n",
    "         [(123.0, 234.0), (123.0, 234.0), (123.0, 234.0)],\n",
    "         True, None),\n",
    "    ]\n",
    "\n",
    "    for i, test in enumerate(test_cases):\n",
    "        l, r, fix, ref_result = test\n",
    "        try:\n",
    "            result = the_estimate_transform(l, r, fix)\n",
    "            if not similar_transform_parameters(result, ref_result):\n",
    "                print(\"Test number %d failed.\" % i)\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(\"Test number %d crashed with exception:\" % i, repr(e))\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "assert(public_test(estimate_transform))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "69ce10e8c3c12934945541a898bdc3c7",
     "grade": false,
     "grade_id": "cell-5c886d436f16631e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that you have implemented `estimate_transform`, you can run the following cell to produce the file `estimate_transform.txt` which we will look at below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each cylinder in the scan, find its cartesian coordinates,\n",
    "# in the world coordinate system.\n",
    "# Find the closest pairs of cylinders from the scanner and cylinders\n",
    "# from the reference, and the optimal transformation which aligns them.\n",
    "# Then, output the scanned cylinders, using this transform.\n",
    "# 04_c_estimate_transform\n",
    "from lego_robot import *\n",
    "from slam_b_library import filter_step, compute_scanner_cylinders,\\\n",
    "    write_cylinders\n",
    "\n",
    "# NOTE: In this notebook you won't have to insert your implementation of find_cylinder_pairs()\n",
    "#       here, since your function from above is just taken. If this does not work, make sure\n",
    "#       to execute the cells above.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # The constants we used for the filter_step.\n",
    "    scanner_displacement = 30.0\n",
    "    ticks_to_mm = 0.349\n",
    "    robot_width = 150.0\n",
    "\n",
    "    # The constants we used for the cylinder detection in our scan.    \n",
    "    minimum_valid_distance = 20.0\n",
    "    depth_jump = 100.0\n",
    "    cylinder_offset = 90.0\n",
    "\n",
    "    # The maximum distance allowed for cylinder assignment.\n",
    "    max_cylinder_distance = 300.0\n",
    "\n",
    "    # The start pose we obtained miraculously.\n",
    "    pose = (1850.0, 1897.0, 3.717551306747922)\n",
    "\n",
    "    # Read the logfile which contains all scans.\n",
    "    logfile = LegoLogfile()\n",
    "    logfile.read(\"robot4_motors.txt\")\n",
    "    logfile.read(\"robot4_scan.txt\")\n",
    "\n",
    "    # Also read the reference cylinders (this is our map).\n",
    "    logfile.read(\"robot_arena_landmarks.txt\")\n",
    "    reference_cylinders = [l[1:3] for l in logfile.landmarks]\n",
    "\n",
    "    out_file = open(\"estimate_transform.txt\", \"w\")\n",
    "    for i in range(len(logfile.scan_data)):\n",
    "        # Compute the new pose.\n",
    "        pose = filter_step(pose, logfile.motor_ticks[i],\n",
    "                           ticks_to_mm, robot_width,\n",
    "                           scanner_displacement)\n",
    "\n",
    "        # Extract cylinders, also convert them to world coordinates.\n",
    "        cartesian_cylinders = compute_scanner_cylinders(\n",
    "            logfile.scan_data[i],\n",
    "            depth_jump, minimum_valid_distance, cylinder_offset)\n",
    "        world_cylinders = [LegoLogfile.scanner_to_world(pose, c)\n",
    "                           for c in cartesian_cylinders]\n",
    "\n",
    "        # For every cylinder, find the closest reference cylinder.\n",
    "        cylinder_pairs = find_cylinder_pairs(\n",
    "            world_cylinders, reference_cylinders, max_cylinder_distance)\n",
    "\n",
    "        # Estimate a transformation using the cylinder pairs.\n",
    "        trafo = estimate_transform(\n",
    "            [world_cylinders[pair[0]] for pair in cylinder_pairs],\n",
    "            [reference_cylinders[pair[1]] for pair in cylinder_pairs],\n",
    "            fix_scale = True)\n",
    "\n",
    "        # Transform the cylinders using the estimated transform.\n",
    "        transformed_world_cylinders = []\n",
    "        if trafo:\n",
    "            transformed_world_cylinders =\\\n",
    "                [apply_transform(trafo, c) for c in\n",
    "                 [world_cylinders[pair[0]] for pair in cylinder_pairs]]            \n",
    "\n",
    "        # Write to file.\n",
    "        # The pose.\n",
    "        print(\"F %f %f %f\" % pose, file=out_file)\n",
    "        # The detected cylinders in the scanner's coordinate system.\n",
    "        write_cylinders(out_file, \"D C\", cartesian_cylinders)\n",
    "        # The detected cylinders, transformed using the estimated trafo.\n",
    "        write_cylinders(out_file, \"W C\", transformed_world_cylinders)\n",
    "\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bb19581f9bf03c23879137e9a901fafa",
     "grade": false,
     "grade_id": "cell-c5ad8dfcf65ae966",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Pose correction from measurement data\n",
    "In this section, we will use the estimated transform to correct the pose of our robot. This is our first step towards using measurement data to estimate the state of the robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dab081e17ac6933bf21091c15940d7d2",
     "grade": false,
     "grade_id": "cell-b8f6f7ca60491351",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# If you don't see a video below, run this cell.\n",
    "from IPython.display import IFrame\n",
    "IFrame(\"https://www.youtube.com/embed/zSUoE-I9kkc\" if \"YouTube\" in globals() else \"//av.tib.eu/player/48985\",\n",
    "       width=560, height=315)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f2fac46058912cc69d2e3332b5a4a9c",
     "grade": false,
     "grade_id": "cell-fe98aef5ecf37db1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### First, as in the video, let's look at the results of the similarity transform estimation.\n",
    "The *assigned landmarks* are marked again, but this time, in a different way!\n",
    "\n",
    "*Previously,* every landmark in the map that was used in an assignment was marked by an extra dot in its center. Even if only one landmark could be assigned, this single landmark was marked (e.g., check above the robot position (step) 63, where only a single landmark is assigned).\n",
    "\n",
    "*Now,* the best transform of the measured landmarks to the map landmarks is computed and applied. So the dots are not in the center of the map landmarks anymore, but rather close to them $-$ as close as possible, in the least squares sense. Also, if less than two landmarks are assigned, the transformation will not be performed and no dots will appear (again, check robot position 63)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipy_logfile_viewer as lfv\n",
    "v = lfv.IPYLogfileViewer(files=[\"estimate_transform.txt\", \"robot_arena_landmarks.txt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7714cd6a361a2352a25adaa6471bb775",
     "grade": false,
     "grade_id": "cell-5f5efdba6900a850",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Next, we correct the pose, in the following assignment (10 Points).\n",
    "As shown in the above video, all there is to do is to implement the `correct_pose(pose, trafo)` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35a636aec4eee8df408b14c8d49be73d",
     "grade": false,
     "grade_id": "cell-1a6ed88741ed6a11",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: In this notebook you won't have to insert your implementation of previous functions\n",
    "#       here, since your functions from above are just taken. If this does not work, make sure\n",
    "#       to execute the cells above.\n",
    "\n",
    "# Correct the pose = (x, y, heading) of the robot using the given\n",
    "# similarity transform. Note this changes the position as well as\n",
    "# the heading.\n",
    "def correct_pose(pose, trafo):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "348e34618b9cb1335c28388b0420beb1",
     "grade": false,
     "grade_id": "cell-4fc0f33271b02201",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### First, let's test your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc4915eab57a7c89641073f0d573f2a2",
     "grade": true,
     "grade_id": "cell-5604d0b953fe0c0d",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from random import random\n",
    "from math import sin, cos, atan2, pi\n",
    "def public_test(the_correct_pose):\n",
    "    number_of_tests = 10\n",
    "    for test in range(number_of_tests):\n",
    "        # Choose a random robot position, in polar coordinates:\n",
    "        # vector lenght and angle.\n",
    "        old_len, old_phi = random()*5, random()*2*pi\n",
    "        # Also choose a random robot heading.\n",
    "        old_heading = random()*2*pi\n",
    "        # From this, define the old pose in Euclidean coordinates.\n",
    "        old_pose = (old_len*cos(old_phi), old_len*sin(old_phi), old_heading)\n",
    "\n",
    "        # Choose a random transformation.\n",
    "        trf_angle = random()*2*pi\n",
    "        trf_scale, trf_x, trf_y = random()+0.5, random()*4-2, random()*6-3\n",
    "        # Convert to our 5-element tuple specification of a trafo.\n",
    "        trf = (trf_scale, cos(trf_angle), sin(trf_angle), trf_x, trf_y)\n",
    "\n",
    "        # Compute the new pose, using polar coordinates.\n",
    "        new_len = old_len * trf_scale\n",
    "        new_phi = old_phi + trf_angle\n",
    "        # From this, define the new pose in Euclidean coordinates.\n",
    "        new_pose = (new_len*cos(new_phi)+trf_x, new_len*sin(new_phi)+trf_y,\n",
    "                    old_heading+trf_angle)\n",
    "\n",
    "        # Now we are ready to run the function to be tested.\n",
    "        # Note for heading, we test cos and sin to prevent mod 2pi ambiguities.\n",
    "        try:\n",
    "            pose = the_correct_pose(old_pose, trf)\n",
    "            if abs(new_pose[0]-pose[0]) > 0.0001 or\\\n",
    "               abs(new_pose[1]-pose[1]) > 0.0001 or\\\n",
    "               abs(cos(new_pose[2])-cos(pose[2])) > 0.0001 or\\\n",
    "               abs(sin(new_pose[2])-sin(pose[2])) > 0.0001:\n",
    "                print(\"Produced the wrong result for:\")\n",
    "                print(\"Initial pose:\", old_pose)\n",
    "                print(\"Transformation:\", trf)\n",
    "                print(\"Expected result:\", new_pose)\n",
    "                print(\"Your result:\", pose)\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(\"Your code crashed with exception:\", repr(e))\n",
    "            return False\n",
    "    return True\n",
    "assert(public_test(correct_pose))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7064d39de170e18fb4943111e5f25675",
     "grade": false,
     "grade_id": "cell-2a5a757150da73d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "After the test works, run the following cell to produce the file `apply_transform.txt` which we will look at below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each cylinder in the scan, find its cartesian coordinates,\n",
    "# in the world coordinate system.\n",
    "# Find the closest pairs of cylinders from the scanner and cylinders\n",
    "# from the reference, and the optimal transformation which aligns them.\n",
    "# Then, use this transform to correct the pose.\n",
    "# 04_d_apply_transform\n",
    "from lego_robot import *\n",
    "from slam_b_library import filter_step, compute_scanner_cylinders,\\\n",
    "    write_cylinders\n",
    "from math import sqrt, atan2\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # The constants we used for the filter_step.\n",
    "    scanner_displacement = 30.0\n",
    "    ticks_to_mm = 0.349\n",
    "    robot_width = 150.0\n",
    "\n",
    "    # The constants we used for the cylinder detection in our scan.    \n",
    "    minimum_valid_distance = 20.0\n",
    "    depth_jump = 100.0\n",
    "    cylinder_offset = 90.0\n",
    "\n",
    "    # The maximum distance allowed for cylinder assignment.\n",
    "    max_cylinder_distance = 400.0\n",
    "\n",
    "    # The start pose we obtained miraculously.\n",
    "    pose = (1850.0, 1897.0, 3.717551306747922)\n",
    "\n",
    "    # Read the logfile which contains all scans.\n",
    "    logfile = LegoLogfile()\n",
    "    logfile.read(\"robot4_motors.txt\")\n",
    "    logfile.read(\"robot4_scan.txt\")\n",
    "\n",
    "    # Also read the reference cylinders (this is our map).\n",
    "    logfile.read(\"robot_arena_landmarks.txt\")\n",
    "    reference_cylinders = [l[1:3] for l in logfile.landmarks]\n",
    "\n",
    "    out_file = open(\"apply_transform.txt\", \"w\")\n",
    "    for i in range(len(logfile.scan_data)):\n",
    "        # Compute the new pose.\n",
    "        pose = filter_step(pose, logfile.motor_ticks[i],\n",
    "                           ticks_to_mm, robot_width,\n",
    "                           scanner_displacement)\n",
    "\n",
    "        # Extract cylinders, also convert them to world coordinates.\n",
    "        cartesian_cylinders = compute_scanner_cylinders(\n",
    "            logfile.scan_data[i],\n",
    "            depth_jump, minimum_valid_distance, cylinder_offset)\n",
    "        world_cylinders = [LegoLogfile.scanner_to_world(pose, c)\n",
    "                           for c in cartesian_cylinders]\n",
    "\n",
    "        # For every cylinder, find the closest reference cylinder.\n",
    "        cylinder_pairs = find_cylinder_pairs(\n",
    "            world_cylinders, reference_cylinders, max_cylinder_distance)\n",
    "\n",
    "        # Estimate a transformation using the cylinder pairs.\n",
    "        trafo = estimate_transform(\n",
    "            [world_cylinders[pair[0]] for pair in cylinder_pairs],\n",
    "            [reference_cylinders[pair[1]] for pair in cylinder_pairs],\n",
    "            fix_scale = True)\n",
    "\n",
    "        # Transform the cylinders using the estimated transform.\n",
    "        transformed_world_cylinders = []\n",
    "        if trafo:\n",
    "            transformed_world_cylinders =\\\n",
    "                [apply_transform(trafo, c) for c in\n",
    "                 [world_cylinders[pair[0]] for pair in cylinder_pairs]]\n",
    "\n",
    "        # Also apply the trafo to correct the position and heading.\n",
    "        if trafo:\n",
    "            pose = correct_pose(pose, trafo)\n",
    "\n",
    "        # Write to file.\n",
    "        # The pose.\n",
    "        print(\"F %f %f %f\" % pose, file=out_file)\n",
    "        # The detected cylinders in the scanner's coordinate system.\n",
    "        write_cylinders(out_file, \"D C\", cartesian_cylinders)\n",
    "        # The detected cylinders, transformed using the estimated trafo.\n",
    "        write_cylinders(out_file, \"W C\", transformed_world_cylinders)\n",
    "\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7968407bb4562073fa3a5fe14ca25d67",
     "grade": false,
     "grade_id": "cell-b88b295c45d9ce5e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Finally, let's celebrate this amazing result!\n",
    "Now, for the first time, you managed to get rid of the drift introduced by the odometry, using the measurements! Comparing the trajectory to the *reference* (obtained by the overhead camera), you see that it fits the global shape quite well.\n",
    "\n",
    "You will also notice that the trajectory looks quite jagged. When you step through the single positions of the robot, you will see that jumps often occur when the set of observed landmarks changes. Sometimes we had quite some luck, for example, from step 69 on, the number of observed landmarks is less than two. From there on, the pose drifts quite a bit. When two landmark matches become available again in step 76, we are quite lucky that the observed landmarks are still close enough to match the landmarks in the map.\n",
    "\n",
    "So far, we did not use any error model. Whenever enough landmarks are matched, we overwrite the pose based on the motion model by the pose based on the transformation estimation. That is, whenever available, we trust our sensor data by a 100%. In later units, we will work on a more sophisticated error model, and we will obtain a less jagged trajectory. However, the basic succession of *predicting* a new pose, *matching* landmarks based on the predicted pose and measurements, and finally *correcting* the pose will stay the same. These are the basic ingredients of what is called a *filter* solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipy_logfile_viewer as lfv\n",
    "v = lfv.IPYLogfileViewer(files=[\"apply_transform.txt\", \"robot4_reference.txt\", \"robot_arena_landmarks.txt\"])"
   ]
  }
 ],
 "metadata": {
  "copyright": "(c) Claus Brenner 2020",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
